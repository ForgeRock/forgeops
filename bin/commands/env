#!/usr/bin/env python3
"""Manage an environment for a ForgeRock deployment"""

import argparse
import datetime
import site
import os
from pathlib import Path
import shutil
import sys
file_name = Path(__file__)
current_file_path = file_name.parent.resolve()
root_dir = [parent_path for parent_path in current_file_path.parents if (parent_path / 'README.md').exists()][0]
dependencies_dir = os.path.join(root_dir, 'lib', 'dependencies')
# Insert lib folders to python path
sys.path.insert(0, str(root_dir))
sys.path.insert(1, str(dependencies_dir) + site.USER_SITE.replace(site.USER_BASE, ''))

# First ensure configure has been executed
from lib.python.ensure_configuration_is_valid_or_exit import ensure_configuration_is_valid_or_exit
try:
    ensure_configuration_is_valid_or_exit()
except Exception as e:
    try:
        print(f'[error] {e.__str__()}')
    except:
        raise e
    sys.exit(1)

try:
    import yaml
    from mergedeep import merge
except:
    print(f'[error] can not load python libraries. Try to run "bin/forgeops-ng configure" and re-run your command')
    sys.exit(1)
import bin.utils as utils


def genDsConnection(name, num, port=1636):
    """Generate a DS connection string to put into base/platform-config.yaml"""

    str=f"{name}-0.{name}:{port}"
    for i in range(1,num-1):
        str += f",{name}-{i}.{name}:{port}"
    return str

# Avoid using anchors/aliases in outputted YAML
# Notice we call this with yaml.dump, but we are still using safe_dump
# From https://ttl255.com/yaml-anchors-and-aliases-and-how-to-disable-them/
class NoAliasDumper(yaml.SafeDumper):
    def ignore_aliases(self, data):
        return True

def writeYamlFile(data, file):
    """Write an object to a yaml file"""
    with open(file, 'w') as f:
        yaml.dump(data, f, sort_keys=False, Dumper=NoAliasDumper)

def process_overlay_dir(path, config, args):
    """Process a dir inside an overlay"""
    skey = str(path.name).replace('-', '_')

    isDS = True if (skey.startswith('ds') and 'snapshot' not in skey) else False
    res_file = 'sts.yaml' if isDS else 'deployment.yaml'

    kust_path = path / 'kustomization.yaml'
    if args.debug: print(f"kust_path={kust_path}")

    if kust_path.is_file():
        if args.debug: print(f"{kust_path} exists")
        kust = yaml.safe_load(open(kust_path))
        if args.namespace:
            if args.debug: print(f"Setting namespace for {skey}")
            kust['namespace'] = args.namespace
        elif args.no_namespace:
            if args.debug: print(f"Removing namespace for {skey}")
            if 'namespace' in kust.keys():
                del kust['namespace']

        if isDS:
            if args.cts_snap_enable and 'ds-cts' in path.name:
                kust['resources'] = utils.replace_or_append_str(kust['resources'], 'ds/snapshot', '../../../base/ds/snapshot/cts')
                kust['patches'] = utils.replace_or_append_str(kust['patches'], 'snapshot-schedule', { 'path': 'snapshot-schedule.yaml' })
            if args.idrepo_snap_enable and 'ds-idrepo' in path.name:
                kust['resources'] = utils.replace_or_append_str(kust['resources'], 'ds/snapshot', '../../../base/ds/snapshot/idrepo')
                kust['patches'] = utils.replace_or_append_str(kust['patches'], 'snapshot-schedule', { 'path': 'snapshot-schedule.yaml' })

        writeYamlFile(kust, kust_path)

    ingress_path = path / 'ingress-fqdn.yaml'
    if args.debug: print(f"ingress_path={ingress_path}")

    if ingress_path.is_file():
        if args.debug: print(f"{ingress_path} exists")
        ingress_class_found = False
        ing = yaml.safe_load(open(ingress_path))
        for idx, item in enumerate(ing):
            if args.fqdn:
                if 'secretName' in item['path'] or item['path'] == '/spec/rules/0/host':
                    ing[idx]['value'] = config['hosts'][0]
                elif 'hosts' in item['path']:
                    ing[idx]['value'] = config['hosts']
            if args.ingress:
                if 'ingressClassName' in item['path']:
                    ingress_class_found = True
                    ing[idx]['value'] = args.ingress

        if args.ingress and not ingress_class_found:
            ing.append({
                'op': 'replace',
                'path': '/spec/ingressClassName',
                'value': args.ingress
            })

        if config['issuer_kind'] and config['issuer_name']:
            issuer = {
                'op': 'add',
                'path': f"/metadata/annotations/cert-manager.io~1{config['issuer_kind']}",
                'value': config['issuer_name']
            }
            issuer_found = False
            for idx, item in enumerate(ing):
                if 'cert-manager' and 'Issuer' in item['path']:
                    if args.debug: print('Found a cert-manager issuer')
                    issuer_found = True
                    ing[idx] = issuer

            if not issuer_found:
                ing.append(issuer)

        writeYamlFile(ing, ingress_path)

    platform_config = path / 'platform-config.yaml'
    if args.debug: print(f"platform_config={platform_config}")

    if skey == 'base' and platform_config.is_file():
        if args.debug: print(f"{platform_config} exists")
        pc = yaml.safe_load(open(platform_config))
        if args.fqdn:
            pc['data']['FQDN'] = config['hosts'][0]

        if 'ds_cts' in config['size'].keys():
            if 'replicaCount' in config['size']['ds_cts'].keys():
                pc['data']['AM_STORES_CTS_SERVERS'] = genDsConnection(
                    name='ds-cts', num=config['size']['ds_cts']['replicaCount'])

        if 'ds_idrepo' in config['size'].keys():
            if 'replicaCount' in config['size']['ds_idrepo'].keys():
                pc['data']['AM_STORES_USER_SERVERS'] = genDsConnection(
                    name='ds-idrepo', num=config['size']['ds_idrepo']['replicaCount'])

        writeYamlFile(pc, platform_config)

    res_path = path / res_file
    if args.debug: print(f"res_path={res_path}")

    if res_path.is_file():
        if args.debug: print(f"{res_path} exists")
        res = yaml.safe_load(open(res_path))

        if skey in config['size'].keys():
            if 'resources' in config['size'][skey].keys():
                res['spec']['template']['spec']['containers'][0]['resources'].update(config['size'][skey]['resources'])
                if isDS:
                    res['spec']['template']['spec']['initContainers'][0]['resources'].update(config['size'][skey]['resources'])
            if isDS and 'volumeClaimSpec' in config['size'][skey].keys():
                res['spec']['volumeClaimTemplates'][0]['spec'].update(config['size'][skey]['volumeClaimSpec'])
            if 'replicaCount' in config['size'][skey].keys():
                res['spec']['replicas'] = config['size'][skey]['replicaCount']

        if config['pull_policy']:
            res['spec']['template']['spec']['containers'][0]['imagePullPolicy'] = config['pull_policy']
            if isDS:
                res['spec']['template']['spec']['initContainers'][0]['imagePullPolicy'] = config['pull_policy']

        writeYamlFile(res, res_path)

    # Look for subdirs and process them
    for d in path.iterdir():
        if args.debug: print(f"d={d}")
        if d.is_file():
            continue
        process_overlay_dir(d, config, args)

def main():
    prog = 'forgeops-ng env'

    parser = argparse.ArgumentParser(description='Manage a ForgeRock Identity Platform environment',
                                     prog=prog,
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--debug', '-d', dest='debug', action='store_true', help='Turn on debugging')
    parser.add_argument('--fqdn', '-f', dest='fqdn', help='Comma separated list of FQDNs')
    parser.add_argument('--helm', '-H', dest='helm', default='helm', help='Dir to store helm values files (absolute or relative to forgeops root)')
    parser.add_argument('--ingress', '-i', dest='ingress', help='Ingress class name')
    parser.add_argument('--kustomize', '-k', dest='kustomize', help='Kustomize dir to use (absolute or relative to forgeops root)')
    parser.add_argument('--namespace', '-n', dest='namespace', help='Namespace to set in the overlay')
    parser.add_argument('--no-namespace', dest='no_namespace', action='store_true', help='Remove namespace from overlay')
    parser.add_argument('--env-name', '-e', dest='env_name', required=True, help='Name of environment to manage')
    parser.add_argument('--single-instance', dest='single', action='store_true', help='Use a single-instance configuration')
    parser.add_argument('--source', '-s', dest='source', help='Name of source kustomize overlay')
    parser.add_argument('--am-cpu', dest='am_cpu', help='Specify CPU setting for am pods')
    parser.add_argument('--am-mem', dest='am_mem', help='Specify memory setting for am pods')
    parser.add_argument('--am-rep', dest='am_rep', type=int, help='Specify replicas for am pods')
    parser.add_argument('--cts-cpu', dest='cts_cpu', help='Specify CPU setting for ds-cts pods')
    parser.add_argument('--cts-disk', dest='cts_disk', help='Specify disk setting for ds-cts pods')
    parser.add_argument('--cts-mem', dest='cts_mem', help='Specify memory setting for ds-cts pods')
    parser.add_argument('--cts-rep', dest='cts_rep', type=int, help='Specify replicas for ds-cts pods')
    parser.add_argument('--cts-snap-enable', dest='cts_snap_enable', action='store_true', help='Enable volume snapshots for ds-cts pods')
    parser.add_argument('--idm-cpu', dest='idm_cpu', help='Specify CPU setting for idm pods')
    parser.add_argument('--idm-mem', dest='idm_mem', help='Specify memory setting for idm pods')
    parser.add_argument('--idm-rep', dest='idm_rep', type=int, help='Specify replicas for idm pods')
    parser.add_argument('--idrepo-cpu', dest='idrepo_cpu', help='Specify CPU setting for ds-idrepo pods')
    parser.add_argument('--idrepo-disk', dest='idrepo_disk', help='Specify disk setting for ds-idrepo pods')
    parser.add_argument('--idrepo-mem', dest='idrepo_mem', help='Specify memory setting for ds-idrepo pods')
    parser.add_argument('--idrepo-rep', dest='idrepo_rep', type=int, help='Specify replicas for ds-idrepo pods')
    parser.add_argument('--idrepo-snap-enable', dest='idrepo_snap_enable', action='store_true', help='Enable volume snapshots for ds-idrepo pods')
    parser.add_argument('--pull-policy', dest='pull_policy', help='Set policy for all platform images')
    parser.add_argument('--no-helm', dest='no_helm', action='store_true', help="Don't create/manage helm values files")
    parser.add_argument('--no-kustomize', dest='no_kustomize', action='store_true', help="Don't create/manage kustomize overlay")
    parser.add_argument('--small', dest='size', action='store_const', const='small', help='A small sized deployment')
    parser.add_argument('--medium', dest='size', action='store_const', const='medium', help='A medium sized deployment')
    parser.add_argument('--large', dest='size', action='store_const', const='large', help='A large sized deployment')
    # Needed to be called from bin/forgeops, but ignored
    parser.add_argument('--dryrun', dest='dryrun', action='store_true', help=argparse.SUPPRESS)
    parser.add_argument('--verbose', dest='verbose', action='store_true', help=argparse.SUPPRESS)

    issuer = parser.add_mutually_exclusive_group()
    issuer.add_argument('--issuer', dest='issuer', help='TLS cert Issuer')
    issuer.add_argument('--cluster-issuer', dest='cluster_issuer', help='TLS cert ClusterIssuer')
    issuer.add_argument('--skip-issuer', dest='skip_issuer', action='store_true', help='Skip TLS cert issuer setup')

    # Flag to skip interactivity for testing
    parser.add_argument('--testing', dest='testing', action='store_true', help=argparse.SUPPRESS)

    args = parser.parse_args()

    if not args.namespace and (args.cts_snap_enable or args.idrepo_snap_enable):
        utils.exit_msg("You must specify a namespace (-n) with --cts-snap-enable and --idrepo-snap-enable")

    config = {}

    config['script_path'] = Path(__file__).parent
    if args.debug: print(f"script_path = {config['script_path']}")
    config['root_path'] = config['script_path'].parent.parent
    if args.debug: print(f"root_path = {config['root_path']}")

    if args.namespace and args.no_namespace:
        utils.exit_msg('Specify --namespace or --no-namespace, not both')

    if args.single and (args.am_rep or args.idm_rep or args.cts_rep or args.idrepo_rep):
        utils.exit_msg('--single-instance is incompatible with *_rep options')

    if '/' in args.env_name:
        utils.exit_msg('Do not use a path with --env-name. It should just be the name of the environment to manage.')

    # Setup defaults for values that can be set in forgeops-ng.conf
    config['helm'] = args.helm
    if os.getenv('HELM_PATH'):
        config['helm'] = os.getenv('HELM_PATH')

    config['kustomize'] = 'kustomize-ng'
    if args.kustomize:
        config['kustomize'] = args.kustomize
    elif os.getenv('KUSTOMIZE_PATH'):
        config['kustomize'] = os.getenv('KUSTOMIZE_PATH')

    config['pull_policy'] = None
    if args.pull_policy:
        config['pull_policy'] = args.pull_policy
    elif os.getenv('PULL_POLICY'):
        config['pull_policy'] = os.getenv('PULL_POLICY')

    config['source'] = 'default'
    if args.source:
        config['source'] = args.source
    elif os.getenv('SOURCE'):
        config['source'] = os.getenv('SOURCE')

    config['do_helm'] = True
    if args.no_helm or os.getenv('NO_HELM') == 'true':
        config['do_helm'] = False

    config['do_kustomize'] = True
    if args.no_kustomize or os.getenv('NO_KUSTOMIZE') == 'true':
        config['do_kustomize'] = False
    # End defaults setup

    config['size'] = {}
    if args.size:
        values_path = config['root_path'] / 'charts' / 'identity-platform' / f'values-{args.size}.yaml'
        config['size'] = yaml.safe_load(open(values_path))

    if args.am_cpu or args.am_mem or args.am_rep or args.single:
        if 'am' not in config['size'].keys():
            config['size']['am'] = {}
            if args.am_cpu or args.am_mem:
                config['size']['am'] = { 'resources': { 'requests': {} } }
                if args.am_mem:
                    config['size']['am']['resources']['limits'] = {}
        if args.am_cpu:
            if args.debug: print(f"am_cpu={args.am_cpu}")
            config['size']['am']['resources']['requests']['cpu'] = args.am_cpu
        if args.am_mem:
            if args.debug: print(f"am_mem={args.am_mem}")
            config['size']['am']['resources']['requests']['memory'] = args.am_mem
            config['size']['am']['resources']['limits']['memory'] = args.am_mem
        if args.am_rep:
            if args.debug: print(f"am_rep={args.am_rep}")
            config['size']['am']['replicaCount'] = int(args.am_rep)
        if args.single:
            config['size']['am']['replicaCount'] = 1

    if args.cts_cpu or args.cts_disk or args.cts_mem or args.cts_rep or args.single:
        if 'ds_cts' not in config['size'].keys():
            config['size']['ds_cts'] = {}
            if args.cts_cpu or args.cts_mem:
                config['size']['ds_cts'] = { 'resources': { 'requests': {} }, }
                if args.cts_mem:
                    config['size']['ds_cts']['resources']['limits'] = {}
            if args.cts_disk:
                config['size']['ds_cts']['volumeClaimSpec'] = { 'resources': { 'requests': {} } }
        if args.cts_cpu:
            if args.debug: print(f"cts_cpu={args.cts_cpu}")
            config['size']['ds_cts']['resources']['requests']['cpu'] = args.cts_cpu
        if args.cts_disk:
            if args.debug: print(f"cts_disk={args.cts_disk}")
            config['size']['ds_cts']['volumeClaimSpec']['resources']['requests']['storage'] = args.cts_disk
        if args.cts_mem:
            if args.debug: print(f"cts_mem={args.cts_mem}")
            config['size']['ds_cts']['resources']['requests']['memory'] = args.cts_mem
            config['size']['ds_cts']['resources']['limits']['memory'] = args.cts_mem
        if args.cts_rep:
            if args.debug: print(f"cts_rep={args.cts_rep}")
            config['size']['ds_cts']['replicaCount'] = int(args.cts_rep)
        if args.single:
            config['size']['ds_cts']['replicaCount'] = 1

    if args.idm_cpu or args.idm_mem or args.idm_rep or args.single:
        if 'idm' not in config['size'].keys():
            config['size']['idm'] = {}
            if args.idm_cpu or args.idm_mem:
                config['size']['idm'] = { 'resources': { 'requests': {} } }
                if args.idm_mem:
                    config['size']['idm']['resources']['limits'] = {}
        if args.idm_cpu:
            if args.debug: print(f"idm_cpu={args.idm_cpu}")
            config['size']['idm']['resources']['requests']['cpu'] = args.idm_cpu
        if args.idm_mem:
            if args.debug: print(f"idm_mem={args.idm_mem}")
            config['size']['idm']['resources']['requests']['memory'] = args.idm_mem
            config['size']['idm']['resources']['limits']['memory'] = args.idm_mem
        if args.idm_rep:
            if args.debug: print(f"idm_rep={args.idm_rep}")
            config['size']['idm']['replicaCount'] = int(args.idm_rep)
        if args.single:
            config['size']['idm']['replicaCount'] = 1

    if args.idrepo_cpu or args.idrepo_disk or args.idrepo_mem or args.idrepo_rep or args.single:
        if 'ds_idrepo' not in config['size'].keys():
            config['size']['ds_idrepo'] = {}
            if args.idrepo_cpu or args.idrepo_mem:
                config['size']['ds_idrepo'] = { 'resources': { 'requests': {} }, }
                if args.idrepo_mem:
                    config['size']['ds_idrepo']['resources']['limits'] = {}
            if args.idrepo_disk:
                config['size']['ds_idrepo']['volumeClaimSpec'] = { 'resources': { 'requests': {} } }
        if args.idrepo_cpu:
            if args.debug: print(f"idrepo_cpu={args.idrepo_cpu}")
            config['size']['ds_idrepo']['resources']['requests']['cpu'] = args.idrepo_cpu
        if args.idrepo_disk:
            if args.debug: print(f"idrepo_disk={args.idrepo_disk}")
            config['size']['ds_idrepo']['volumeClaimSpec']['resources']['requests']['storage'] = args.idrepo_disk
        if args.idrepo_mem:
            if args.debug: print(f"idrepo_mem={args.idrepo_mem}")
            config['size']['ds_idrepo']['resources']['requests']['memory'] = args.idrepo_mem
            config['size']['ds_idrepo']['resources']['limits']['memory'] = args.idrepo_mem
        if args.idrepo_rep:
            if args.debug: print(f"idrepo_rep={args.idrepo_rep}")
            config['size']['ds_idrepo']['replicaCount'] = int(args.idrepo_rep)
        if args.single:
            config['size']['ds_idrepo']['replicaCount'] = 1

    values_ingress = {}
    config['hosts'] = None
    if args.fqdn:
        config['hosts'] = args.fqdn.split(',')
        if args.debug: print(f"hosts={config['hosts']}")
        values_ingress = {
            'platform': {
                'ingress': {
                    'hosts': config['hosts']
                }
            }
        }

    if args.ingress:
        if 'platform' not in values_ingress.keys():
           values_ingress['platform'] = { 'ingress': {} }
        values_ingress['platform']['ingress']['className'] = args.ingress

    config['issuer_kind_ann'] = None
    config['issuer_kind'] = None
    config['issuer_name'] = None
    if args.issuer or args.cluster_issuer:
        if args.issuer:
            config['issuer_kind_ann']  = 'issuer'
            config['issuer_kind'] = 'Issuer'
            config['issuer_name'] = args.issuer
        elif args.cluster_issuer:
            config['issuer_kind_ann']  = 'cluster-issuer'
            config['issuer_kind'] = 'ClusterIssuer'
            config['issuer_name'] = args.cluster_issuer

    values_images = {}
    if config['pull_policy']:
        values_images = {
            'am': { 'image': {} },
            'amster': { 'image': {} },
            'ds_cts': { 'image': {} },
            'ds_idrepo': { 'image': {} },
            'ds_snapshot': { 'image': {} },
            'idm': { 'image': {} },
            'ig': { 'image': {} },
            'ldif_importer': { 'image': {} },
            'admin_ui': { 'image': {} },
            'end_user_ui': { 'image': {} },
            'login_ui': { 'image': {} },
        }
        values_images['am']['image']['pullPolicy'] = config['pull_policy']
        values_images['amster']['image']['pullPolicy'] = config['pull_policy']
        values_images['ds_cts']['image']['pullPolicy'] = config['pull_policy']
        values_images['ds_idrepo']['image']['pullPolicy'] = config['pull_policy']
        values_images['idm']['image']['pullPolicy'] = config['pull_policy']
        values_images['ldif_importer']['image']['pullPolicy'] = config['pull_policy']
        values_images['admin_ui']['image']['pullPolicy'] = config['pull_policy']
        values_images['end_user_ui']['image']['pullPolicy'] = config['pull_policy']
        values_images['login_ui']['image']['pullPolicy'] = config['pull_policy']
        values_images['ig']['image']['pullPolicy'] = config['pull_policy']
        values_images['ds_snapshot']['image']['pullPolicy'] = config['pull_policy']

    values_snap = {}
    if args.cts_snap_enable:
        values_snap['ds_cts'] = {
            'snapshot': {
                'enabled': True
            }
        }
    if args.idrepo_snap_enable:
        values_snap['ds_idrepo'] = {
            'snapshot': {
                'enabled': True
            }
        }

    if Path(config['kustomize']).is_absolute():
        config['kustomize_path'] = Path(config['kustomize'])
    else:
        config['kustomize_path'] = config['root_path'] / config['kustomize']
    if args.debug: print(f"kustomize_path={config['kustomize_path']}")
    if not config['kustomize_path'].is_dir():
       utils.exit_msg(f"Kustomize dir ({config['kustomize_path']}) isn't a dir or doesn't exist")

    config['overlay_root'] = config['kustomize_path'] / 'overlay'
    if not config['overlay_root'].is_dir():
       utils.exit_msg(f"Overlay root ({config['overlay_root']}) isn't a dir or doesn't exist")

    config['overlay_path'] = config['overlay_root'] / args.env_name
    if args.debug: print(f"overlay_path={config['overlay_path']}")

    if Path(config['source']).is_absolute():
        config['source_path'] = Path(config['source'])
    else:
        config['source_path'] = config['overlay_root'] / config['source']
    if args.debug: print(f"source_path={config['source_path']}")

    # Check if we are Creating or Updating
    config['kustomize_action'] = None
    if config['do_kustomize']:
        config['kustomize_action'] = 'Create'
        if config['overlay_path'].is_dir():
            print('Updating existing overlay.')
            config['kustomize_action'] = 'Update'
        elif config['overlay_path'].is_file():
            utils.exit_msg('Overlay exists as a file. Remove it and try again')
        elif not args.fqdn:
            utils.exit_msg('An FQDN is required when generating a new overlay')
        else:
            msg = f"""
Creating new overlay
From: {config['source_path']}
To: {config['overlay_path']}
"""
            print(msg)

    config['helm_action'] = None
    config['helm_path'] = None
    if config['do_helm']:
        config['helm_action'] = 'Create'
        if Path(config['helm']).is_absolute():
            config['helm_path'] = Path(config['helm'])
        else:
            config['helm_path'] = config['root_path'] / config['helm']
        if config['helm_path'].is_dir():
            config['helm_path'] = config['helm_path'] / args.env_name
        else:
            utils.exit_msg(f"Helm path doesn't exist or isn't a dir: {config['helm_path']}")
        if args.debug: print(f"helm_path={config['helm_path']}")

        values_file = config['helm_path'] / 'values.yaml'
        if args.debug: print(f"values_file={values_file}")
        if config['helm_path'].is_dir():
            if values_file.is_file():
                print('Updating existing helm values.')
                config['helm_action'] = 'Update'
            else:
                print('Helm environment dir exists, but has no values.yaml.')
        elif config['helm_path'].is_file():
            utils.exit_msg('Helm path exists as a file. Remove it and try again.')
        else:
            print(f"{config['helm_path']} not found, creating.")
            config['helm_path'].mkdir(mode=0o750, parents=True)

    do_create = False
    if config['helm_action'] == 'Create' or config['kustomize_action'] == 'Create':
        do_create = True
    # Finish Create or Update check

    if not do_create and bool(config['size']):
        msg = f"""
You are changing the size of an existing environment. If you have already deployed the environment, there could be extra steps needed to apply the size changes. In particular, when changing the size of your DS PVCs you will need to delete the changed StatefulSet(s) and re-deploy them. Any existing PVCs will need to be edited manually and resized. Refer to Kubernetes docs on resizing PVCs for more information.

If you have not yet deployed the environment, then you can ignore this message.
"""
        print(msg)

    if do_create and not args.skip_issuer and not args.issuer and not args.cluster_issuer:
        msg = f"""
When creating a new environment, it's best practice to specify a HTTPS certificate issuer (--issuer or --cluster-issuer). You can also skip issuer creation with --skip-issuer. For demos, you can use 'bin/certmanager-deploy.sh' to deploy cert-manager and create a self-signed ClusterIssuer called 'default-issuer'.

"""
        print(msg)

        use_default_issuer = False
        if args.testing:
            use_default_issuer = True
        elif input('Continue using a ClusterIssuer called "default-issuer"? [Y/N] ').lower() in ['yes', 'y']:
            use_default_issuer = True
        else:
            utils.exit_msg('Please rerun with --issuer, --cluster-issuer, or --skip-issuer')

        if use_default_issuer:
            config['issuer_kind_ann'] = 'cluster-issuer'
            config['issuer_kind'] = 'ClusterIssuer'
            config['issuer_name'] = 'default-issuer'
            print(f"Using {config['issuer_kind']}: {config['issuer_name']}")

    ###
    ### Configure kustomize overlay
    ###
    if config['do_kustomize']:
        if config['kustomize_action'] == 'Create':
            if config['source_path'].is_dir():
                shutil.copytree(config['source_path'], config['overlay_path'])
            elif config['source_path'].is_file():
                utils.exit_msg(f"Source overlay isn't a directory: {config['source_path']}")
            else:
                utils.exit_msg(f"Source overlay doesn't exist: {config['source_path']}")

        if args.cts_snap_enable or args.idrepo_snap_enable:
            kust_path = config['overlay_path'] / 'kustomization.yaml'
            if kust_path.is_file():
                kust = yaml.safe_load(open(kust_path))
                kust['resources'] = utils.replace_or_append_str(kust['resources'], 'ds-snapshot', './ds-snapshot')
                writeYamlFile(kust, kust_path)

            rbac_ns_path = config['overlay_path'] / 'ds-snapshot' / 'rbac' / 'namespace.yaml'
            if rbac_ns_path.is_file():
                rbac_ns = yaml.safe_load(open(rbac_ns_path))
                rbac_ns['subjects'] = utils.replace_or_append_dict(rbac_ns['subjects'], 'name', 'ds-snapshot', 'namespace', args.namespace)
                writeYamlFile(rbac_ns, rbac_ns_path)

        process_overlay_dir(config['overlay_path'], config, args)


    ###
    ### Setup helm values files
    ###
    if config['do_helm']:
        if config['issuer_name'] and config['issuer_kind']:
            if 'platform' not in values_ingress.keys():
               values_ingress['platform'] = { 'ingress': { 'tls': { 'issuer': {} } } }
            elif 'ingress' not in values_ingress['platform'].keys():
               values_ingress['platform']['ingress'] = { 'tls': { 'issuer': {} } }
            else:
               values_ingress['platform']['ingress']['tls'] = { 'issuer': {} }
            values_ingress['platform']['ingress']['tls']['issuer']['kind'] = config['issuer_kind']
            values_ingress['platform']['ingress']['tls']['issuer']['name'] = config['issuer_name']

        values = {}
        if values_file.is_file():
            values = yaml.safe_load(open(values_file))
        merge(values, config['size'], values_ingress, values_images, values_snap)
        writeYamlFile(values, values_file)

    ###
    ### Logs
    ###
    timestamp = datetime.datetime.now(datetime.timezone.utc).strftime("%Y%m%d-%H:%M:%S%z")
    cmd_ary = sys.argv
    cmd_ary[0] = prog
    cmd = ' '.join(cmd_ary)
    log_file = 'env.log'
    if config['do_kustomize']:
        k_log_line = f"{timestamp} {config['kustomize_action']} {cmd}"
        log_path_overlay = config['overlay_path'] / log_file
        with open(log_path_overlay, 'a') as log_overlay_f:
            log_overlay_f.write(f"{k_log_line}\n")
    if config['do_helm']:
        h_log_line = f"{timestamp} {config['helm_action']} {cmd}"
        log_path_helm = config['helm_path'] / log_file
        with open(log_path_helm, 'a') as log_helm_f:
            log_helm_f.write(f"{h_log_line}\n")


if __name__ == '__main__':
    main()
