apiVersion: batch/v1
kind: Job
metadata:
  name: export-ldif
spec:
  template:
    spec:
      restartPolicy: Never
      initContainers:
      # Run the export as an init container. We can kubectl wait for completion in scripts
      - name: export
        image: us-docker.pkg.dev/forgeops-public/images/ds-idrepo:7.1.7
        imagePullPolicy: IfNotPresent
        args: ["/opt/scripts/export-ldif.sh", "/mnt/export/ldif"]
        # Must mount the data, and the keystore secrets to read the data
        volumeMounts:
        - name: data
          mountPath: /opt/opendj/data
        - name: secrets
          mountPath: /opt/opendj/secrets
        - name: scripts
          mountPath: /opt/scripts
      # The volume to export the ldif to
        - name: ldif
          mountPath: /mnt/export
      containers:
      # Example of a main container. This does nothing but sleep
      # You can kubectl cp the files from /data/ldif
      # - name: busybox
      #   image: busybox
      #   command: ["/bin/sh"]
      #   args: ["-c", "sleep 60"]

      # An example of using the gsutil to copy the files to cloud storage
      - name: gsutil
        image: gcr.io/google.com/cloudsdktool/cloud-sdk:slim
        command: ['/opt/scripts/gs-backup.sh']
        # If you use workload identity, mounting the service account is not required
        # env:
        # - name: GOOGLE_APPLICATION_CREDENTIALS
        #   value: /var/run/secrets/service-account.json
        volumeMounts:
        - name: ldif
          mountPath: /data
        - name: config
          mountPath: /.config
        - name: scripts
          mountPath: /opt/scripts
        # Not needed for workload identity
        # - name: sa
        #   mountPath: /var/run/secrets
      securityContext:
        fsGroup: 0
        runAsUser: 11111
      serviceAccount: ldif-sa
      volumes:
      - name: data
        persistentVolumeClaim:
          # Mounts the data from a clone or a snapshot of the data pvc
          # The CSI driver must support cloning
          claimName: ds-data-clone
          # This example mounts the DS data pvc directly which means DS can not
          # be running when you do the export.
          # claimName: data-ds-idrepo-0
      - name: ldif
        persistentVolumeClaim:
          claimName: export-ldif
      - name: secrets
        secret:
          secretName: ds
      - name: scripts
        configMap:
          name: export-scripts
          defaultMode: 0755
      # If using workload identity you do not need the service account
      # - name: sa
      #   secret:
      #     secretName: gcs-secret
      - name: config
        emptyDir:
          {}
